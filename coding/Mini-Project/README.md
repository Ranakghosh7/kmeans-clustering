# Bias-Aware Automated Feedback System for Student Writing

## ğŸ“Œ Project Overview

This repository contains a research-oriented NLP project designed to generate high-quality writing feedback **while detecting and mitigating potential linguistic or demographic biases**. The project is structured like an academic study to strengthen research experience for programs such as **Caltech SURF**.

---

## ğŸ¯ Objectives

* Build a baseline automatic writing feedback generator.
* Detect bias using sentiment shifts, toxicity scoring, and demographic swap tests.
* Implement mitigation strategies to reduce unfair or biased behaviors.
* Compare baseline vs. bias-aware feedback systems.
* Present results through experiments, analysis, and visualizations.

---

## ğŸ§  Research Questions

1. Can an LLM provide useful feedback while actively monitoring for bias?
2. Does a structured bias mitigation pipeline improve fairness?
3. Do mitigation strategies affect feedback quality?

---

## ğŸ“‚ Repository Structure

```
bias-aware-feedback-nlp/
â”‚â”€â”€ README.md
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ raw_samples/
â”‚   â”œâ”€â”€ bias_test_pairs/
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ bias_detector.py
â”‚   â”œâ”€â”€ mitigation.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ utils.py
â”‚â”€â”€ notebooks/
â”‚   â”œâ”€â”€ baseline_experiments.ipynb
â”‚   â”œâ”€â”€ bias_tests.ipynb
â”‚   â””â”€â”€ mitigation_ablation.ipynb
â”‚â”€â”€ results/
â”‚   â”œâ”€â”€ plots/
â”‚   â””â”€â”€ metrics/
â”‚â”€â”€ demo/
â”‚   â””â”€â”€ app.py
â”‚â”€â”€ paper/
â”‚   â””â”€â”€ mini_research_report.pdf
```

---

## ğŸ”§ Methodology Overview

### 1. Data Collection

* Collect public writing samples.
* Create paired samples with demographic swaps.

### 2. Baseline Feedback Generator

* LLM-based writing feedback.
* Raw, no mitigation.

### 3. Bias Detection Module

* Sentiment analysis
* Toxicity classification
* Politeness scoring
* Demographic swap consistency checks

### 4. Bias Mitigation

* Prompt constraints
* Re-ranking
* Filtering strategies

### 5. Evaluation

* Quality metrics
* Fairness metrics
* Explainability outputs

---

## ğŸ“Š Planned Experiments

### **Experiment 1 â€” Baseline vs Bias-Aware System**

Compare suggestion quality and fairness.

### **Experiment 2 â€” Swap-Test Evaluation**

Measure sentiment and style shifts across demographic variants.

### **Experiment 3 â€” Ablation Study**

Evaluate which mitigation components contribute most to fairness.

---

## ğŸš€ Getting Started

### Prerequisites

* Python 3.9+
* PyTorch
* HuggingFace Transformers
* SpaCy
* FairLearn / AIF360
* Streamlit

### Installation

```
git clone https://github.com/Ranakghosh7/bias-aware-feedback-nlp.git
cd bias-aware-feedback-nlp
pip install -r requirements.txt
```

### Run Streamlit Demo

```
streamlit run demo/app.py
```

---

## ğŸ“ To-Do

* [ ] Add initial dataset samples
* [ ] Implement baseline generator
* [ ] Build bias detection module
* [ ] Add mitigation strategies
* [ ] Conduct experiments
* [ ] Add results and plots
* [ ] Write full research paper

---

## ğŸ“„ License

MIT License

---

## âœ¨ Author

This project was created as part of a research portfolio for competitive undergraduate research opportunities.
